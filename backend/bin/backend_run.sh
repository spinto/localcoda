#/bin/bash
#Run for debug and test

#Basic functions
function error(){
  echo "ERROR: $2" >&2
  exit $1
}
function log(){
  [[ $LOGLEVEL -ge 1 ]] && echo $* >&2
}
function check_sw(){
  for sw in $*; do
		which $sw &>/dev/null
    [[ $? -ne 0 ]] && error 2 "$sw not found in the PATH. This is required."
  done
}
function check_env(){
  for c in $*; do
    eval [[ -z "\$$c" ]] && error 3 "Configuration value of $c not set. Please set it in the $APPDIR/cfg/conf file!"
  done
}

#Check basic software is there
check_sw jq grep date wc

#Get app directory and load basic configuration
SWDIR="${BASH_SOURCE[0]}"
[[ "${SWDIR:0:1}" == "/" ]] || SWDIR="$PWD/$SWDIR"
cd "${SWDIR%/*}"; SWDIR="$PWD"
APPDIR="${SWDIR%/*}"
[[ -e "$APPDIR/cfg/conf" ]] || error 1 "Cannot find configuration file at $APPDIR/cfg/conf"
source $APPDIR/cfg/conf

#Load commandline options
APP_VERSION=0.0.2
function usage {
  cat <<:usage
localcoda backend run version $APP_VERSION
Usage:
  backend_run [options] <tutorial-dir> [<index-file>]

Where the arguments are:
  <tutorial-dir> is the main directory for your tutorials, relative to the TUTORIALS_VOLUME
                 volume containing the tutorials. For local orchestrator, you can use an
                 absolute path, pointing to the local disk instead than TUTORIALS_VOLUME.
  <index-file>   [optional] is the path of the index file relative to the <tutorial-dir>.
                 Defaults to "index.json". This is useful when you have several scenarios
                 in the same tutorial directory.

Options:
  -h             displays this help page
  -o <key>=<val> override the configuration option (in the $APPDIR/cfg/conf file). See
                 the content of the $APPDIR/cfg/conf file for specific options to override
  -u <uuid>      use a custom UUID (instead of the one automatically generated by this script)
  -U <username>  assign the running instance to a given <username>. Useful if you are managing
                 multi-tenant executions
  -q | -v        decrease (-q) or increase (-v) log level
  -d | --nowait  do not wait for the backend to be ready before closing the app. The script
                 will release once the backend is started, and you can check its status via
                 the backend_ls command
  -Ldev          enable development mode. This will directly mount in read/write the frontend directories from
                 this repository instead of the ones in the image. Only for development and only
                 for local orchestrator.
:usage
  exit 1
}

TUTORIAL_DIR=
INDEX_FILE=
LOCAL_UUID=
WAIT_FOR_START=true
INSTANCE_USERNAME=
LOGLEVEL=1
LOCAL_DEV_MODE=false
[[ -z "$*" ]] && usage
while [[ "$#" -gt 0 ]]; do
  case "$1" in
   -o) eval "$2"; shift 2 ;;
   -u) LOCAL_UUID="$2"; shift 2 ;;
   -U) INSTANCE_USERNAME="$2"; shift 2 ;;
   -d | --nowait) WAIT_FOR_START=false; shift 1 ;;
   -v) LOGLEVEL=$(( LOGLEVEL + 1 )); shift 1;;
   -q) LOGLEVEL=$(( LOGLEVEL - 1 )); shift 1;;
   -Ldev) LOCAL_DEV_MODE=true; shift 1;;
   -h | --help) usage ;;
   *) if [[ -z "$TUTORIAL_DIR" ]]; then
	      TUTORIAL_DIR="${1%/}"
				[[ -z "$TUTORIAL_DIR" ]] && TUTORIAL_DIR=" "
      elif [[ -z "$INDEX_FILE" ]]; then
			  INDEX_FILE="$1"
      else
        error 1 "Unrecognized argument $1. See help!"
      fi
      shift 1
    ;;
  esac
done
[[ "$TUTORIAL_DIR" == " " ]] && TUTORIAL_DIR=
#Check required configuration is set
check_env VIRT_ENGINE IMAGES_${VIRT_ENGINE^^}_MAPFILE EXT_DOMAIN_NAME EXT_PROTO EXT_FT_MAINHOST_SCHEME EXT_BK_MAINHOST_SCHEME EXT_BK_PROXYHOST_SCHEME TUTORIAL_MAX_TIME ORCHESTRATION_ENGINE EXECUTION_NAME_SCHEME REMOTE_PORT TUTORIALS_VOLUME
if [[ $ORCHESTRATION_ENGINE == "local" ]]; then
  check_sw docker
	check_env LOCAL_INT_IPPORT
elif [[ $ORCHESTRATION_ENGINE == "kubernetes" ]]; then
  check_sw kubectl
	check_env KUBERNETES_NAMESPACE 
else
	error 2 "Orchestration engine $ORCHESTRATION_ENGINE is invalid!"
fi
if [[ $VIRT_ENGINE == "docker" ]]; then
  IMAGES_MAPFILE=$IMAGES_DOCKER_MAPFILE
elif [[ $VIRT_ENGINE == "sysbox" ]]; then
  IMAGES_MAPFILE=$IMAGES_SYSBOX_MAPFILE
else
  error 2 "Virtualization engine $VIRT_ENGINE is invalid!"
fi
eval IMAGES_MAPFILE="\$IMAGES_${VIRT_ENGINE^^}_MAPFILE"
[[ "${IMAGES_MAPFILE:0:1}" != "/" ]] && IMAGES_MAPFILE="$APPDIR/$IMAGES_MAPFILE"
[[ -f "$IMAGES_MAPFILE" ]] || error 33 "Cannot find image mapfile $IMAGES_MAPFILE"

#Set defaults
[[ -z "$INDEX_FILE" ]] && INDEX_FILE="index.json"
if [[ -z "$LOCAL_UUID" ]]; then
  LOCAL_UUID=
  function uidg(){
    C="89ab"
    for ((N=0;N<16;++N)); do
      B="$((RANDOM%256))"
      case "$N" in
        6)  printf '4%x' "$((B%16))" ;;
        8)  printf '%c%x' "${C:$RANDOM%${#C}:1}" "$((B%16))" ;;
        3|5|7|9) printf '%02x-' "$B" ;;
        *)  printf '%02x' "$B" ;;
      esac
    done
  }
  LOCAL_UUID=`uidg`
fi

#Calculate execution container name (using the UUID)
eval EXECUTION_NAME=$EXECUTION_NAME_SCHEME

#Load the backend run information. For this we need to access the tutorial index file.
if [[ "${TUTORIAL_DIR:0:1}" == "/" ]]; then
  #This is a local path, you can mount it only in the local orchestrator and no subpath is present
	[[ $ORCHESTRATION_ENGINE == "local" ]] || error 3 "You can use a local tutorial path only for the local orchestration engine"
  #Check if tutorial exists and extract image backend info
  [[ -f "$TUTORIAL_DIR/$INDEX_FILE" ]] || error 1 "Invalid tutorial folder or scenario path provided. No index.json!"
  BACKEND_INFO=( `jq -r '.backend.imageid + " " + .backend.mountmode' < $TUTORIAL_DIR/$INDEX_FILE` )

else
  #The tutorial is in a path relative to a volume. We need still to resolve it to check the tutorial exists and to get the image id from it

  #Check if tutorial exists and extract image backend info
	if [[ -n "$TUTORIALS_VOLUME_ACCESS_MOUNT" ]]; then
    #Tutorial volume is mounted locally. Access it from local dir.
		[[ -f "$TUTORIALS_VOLUME_ACCESS_MOUNT/$TUTORIAL_DIR/$INDEX_FILE" ]] || error 1 "Cannot find scenario path index.json in local tutorial mount!"
		BACKEND_INFO=( `jq -r '.backend.imageid + " " + .backend.mountmode' < $TUTORIALS_VOLUME_ACCESS_MOUNT/$TUTORIAL_DIR/$INDEX_FILE` )
	elif [[ -n "$TUTORIALS_VOLUME_ACCESS_IMAGE" ]]; then
    #Tutorial volume need to be accessed remotely. we spawn a container to do so
    if [[ $ORCHESTRATION_ENGINE == "local" ]]; then
			BACKEND_INFO=( `docker run --rm -v $TUTORIALS_VOLUME:/data/tutorials:ro "$TUTORIALS_VOLUME_ACCESS_IMAGE" cat /data/tutorials/$TUTORIAL_DIR/$INDEX_FILE 2>/dev/null | jq -r '.backend.imageid + " " + .backend.mountmode'` )
			[[ ${PIPESTATUS[0]} -ne 0 || -z "$BACKEND_INFO" ]] && error 1 "Cannot find scenario index.json in TUTORIALS_VOLUME. If this is a local scenario, use an absolute path!"
    elif [[ $ORCHESTRATION_ENGINE == "kubernetes" ]]; then
	    log "Warning: using the kubernetes engine without a locally mounted tutorials volume is slow and not recommended. Set the TUTORIALS_VOLUME_ACCESS_MOUNT option to a local path mounting or mirroring your tutorials"
			log "Starting tutorial access helper pod..."
      cat <<EOF | kubectl -n "$KUBERNETES_NAMESPACE" apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: $EXECUTION_NAME-helper
spec:
  containers:
  - name: helper
    image: $TUTORIALS_VOLUME_ACCESS_IMAGE
    command: ["/bin/sh", "-c", "read -u 2"]
    volumeMounts:
    - mountPath: /data/tutorials
      name: tutorials-path
  volumes:
  - name: tutorials-path
    persistentVolumeClaim:
      claimName: $TUTORIALS_VOLUME
EOF
      [[ $? -ne 0 ]] && error 3 "Failed to create helper pod!"
      kubectl -n "$KUBERNETES_NAMESPACE" wait --for=condition=Ready pod/$EXECUTION_NAME-helper --timeout=60s
      [[ $? -ne 0 ]] && error 3 "Helper pod did not start. Maybe something is wrong with your PVC!"
      #Access the file
      log "Getting tutorial info..."
  		BACKEND_INFO=( `kubectl -n "$KUBERNETES_NAMESPACE" exec pod/$EXECUTION_NAME-helper -- /bin/cat /data/tutorials/$TUTORIAL_DIR/$INDEX_FILE | jq -r '.backend.imageid + " " + .backend.mountmode'` )
      res=${PIPESTATUS[0]}
			#Remove the pod
      log "Cleaning up..."
      kubectl -n "$KUBERNETES_NAMESPACE" delete pod/$EXECUTION_NAME-helper
      #Check we have the info
			[[ $res -ne 0 || -z "$BACKEND_INFO" ]] && error 1 "Invalid tutorial folder or file path provided. No index.json!"
    else
		  error 12 "This mode is not supported with $ORCHESTRATION_ENGINE orchestration engine"
    fi
	else
		error 14 "You need to set one of TUTORIALS_VOLUME_ACCESS_MOUNT or TUTORIALS_VOLUME_ACCESS_IMAGE options to use tutorial volumes."
	fi
fi
BACKEND_IMAGE="${BACKEND_INFO[0]}"
BACKEND_T_MODE="${BACKEND_INFO[1]}"
[[ "$BACKEND_T_MODE" == "rw" ]] || BACKEND_T_MODE=ro

#Look if the image to run is into your mapfile
IMAGE_INFO="`grep "^$BACKEND_IMAGE " $IMAGES_MAPFILE`"
[[ -z "$IMAGE_INFO" ]] && error 33 "Tutorial image backend is $IMAGE_BACKEND, but $IMAGE_BACKEND is not in the $IMAGES_MAPFILE"
IMAGE_INFO=( $IMAGE_INFO )
IMAGE_TORUN="${IMAGE_INFO[1]}"
IMAGE_HOSTNAME="${IMAGE_INFO[2]}"
IMAGE_MEMORY_LIMIT="${IMAGE_INFO[3]}"
IMAGE_CPU_LIMIT="${IMAGE_INFO[4]}"
for c in IMAGE_TORUN IMAGE_HOSTNAME IMAGE_MEMORY_LIMIT IMAGE_CPU_LIMIT; do
  eval [[ -z "\$$c" ]] && error 3 "Invalid $IMAGES_MAPFILE entry for $c not set. Image is not found or parameter is missing!"
done

#Calculate external domain name (if required)
if [[ "$EXT_DOMAIN_NAME" =~ NIP_ADDRESS ]]; then
  check_sw hostname awk
  #Generate nip address hash
  NIP_ADDRESS="`hostname -I | awk '{split($1, a, "."); printf("%02x%02x%02x%02x.nip.io\n", a[1], a[2], a[3], a[4])}'`"
  eval EXT_DOMAIN_NAME=$EXT_DOMAIN_NAME
fi

#Get application paths from schemes
eval EXT_EXITHOST=$EXT_FT_MAINHOST_SCHEME
eval EXT_MAINHOST=$EXT_BK_MAINHOST_SCHEME
PORT="PORT"
eval EXT_PROXYHOST=$EXT_BK_PROXYHOST_SCHEME
READY_URL="$EXT_PROTO://$EXT_MAINHOST/"

#Use the orchestration engine to run the backend instance
if [[ $ORCHESTRATION_ENGINE == "local" ]]; then

  #Determine the tutorials mount points
  if [[ "${TUTORIAL_DIR:0:1}" == "/" ]]; then
    #This is a local bind mount
	  DOCKER_RUN_ARGS="--mount type=bind,src=$TUTORIAL_DIR,dst=/etc/localcoda/tutorial"
	else
    #This is a volume mount, with an optional sub dir
		DOCKER_RUN_ARGS="--mount type=volume,src=$TUTORIALS_VOLUME,dst=/etc/localcoda/tutorial,volume-subpath=$TUTORIAL_DIR"
	fi
  [[ "$BACKEND_T_MODE" == "rw" ]] || DOCKER_RUN_ARGS="$DOCKER_RUN_ARGS,ro"

  #Get runtime engine
  if [[ $VIRT_ENGINE == "docker" ]]; then
    DOCKER_RUN_ARGS="$DOCKER_RUN_ARGS --privileged --cgroupns=host"
  elif [[ $VIRT_ENGINE == "sysbox" ]]; then
    DOCKER_RUN_ARGS="$DOCKER_RUN_ARGS --runtime=sysbox-runc"
  else
    error 32 "Virtualization engine $VIRT_ENGINE not supported in local mode"
	fi

  #Add username label
  if [[ -n "$INSTANCE_USERNAME" ]]; then
    DOCKER_RUN_ARGS="$DOCKER_RUN_ARGS -l user=$INSTANCE_USERNAME"
    #Check maximum parallel executions (if reached)
    if [[ -n "$MAXIMUM_RUN_PER_USER" && "$MAXIMUM_RUN_PER_USER" -gt 0 ]]; then
      running_instances="`docker ps -q -f "label=user=$INSTANCE_USERNAME" | wc -l`"
      [[ "$running_instances" -ge "$MAXIMUM_RUN_PER_USER" ]] && error 42 "Maximum runs per user reached"
    fi
  fi

  #Add memory and cpu limits, if any
  [[ -n "$IMAGE_CPU_LIMIT" && "$IMAGE_CPU_LIMIT" -ne 0 ]] && DOCKER_RUN_ARGS="$DOCKER_RUN_ARGS --cpus=$IMAGE_CPU_LIMIT"
  [[ -n "$IMAGE_MEMORY_LIMIT" && "$IMAGE_MEMORY_LIMIT" -ne 0 ]] && DOCKER_RUN_ARGS="$DOCKER_RUN_ARGS --memory=$IMAGE_MEMORY_LIMIT"

  #Check if I have to pick up a port and if so, do so
  if [[ "$LOCAL_INT_IPPORT" =~ RANDOM_PORT ]]; then
    check_env LOCAL_RANDOMPORT_MIN LOCAL_RANDOMPORT_MAX
    #Pick a random port
    RANDOM_PORT=
    while [[ -z "$RANDOM_PORT" ]]; do
      RANDOM_PORT=$(( RANDOM  % ( LOCAL_RANDOMPORT_MAX - LOCAL_RANDOMPORT_MIN + 1 ) + LOCAL_RANDOMPORT_MIN ))
      (echo >/dev/tcp/127.0.0.1/$RANDOM_PORT) &>/dev/null || break
    done
    #Get the new ipport
    eval LOCAL_INT_IPPORT=$LOCAL_INT_IPPORT
    #Recreate all the access schemas
    if [[ "$LOCAL_INT_F_PROXY" == "true" ]]; then
      EXT_DOMAIN_NAME="$RANDOM_PORT.$EXT_DOMAIN_NAME"
      EXT_BK_MAINHOST_SCHEME="${EXT_BK_MAINHOST_SCHEME//.\$EXT_DOMAIN_NAME/-\$EXT_DOMAIN_NAME}"
      EXT_BK_PROXYHOST_SCHEME="${EXT_BK_PROXYHOST_SCHEME//.\$EXT_DOMAIN_NAME/-\$EXT_DOMAIN_NAME}"
    else
      EXT_DOMAIN_NAME="$EXT_DOMAIN_NAME:$RANDOM_PORT"
    fi
    eval EXT_MAINHOST=$EXT_BK_MAINHOST_SCHEME
    PORT="PORT"
    eval EXT_PROXYHOST=$EXT_BK_PROXYHOST_SCHEME
    READY_URL="$EXT_PROTO://$EXT_MAINHOST/"
  fi

  #Check local development mode
  if [[ "$LOCAL_DEV_MODE" == "true" ]]; then
    #Mount the www folder from disk
    DOCKER_RUN_ARGS="$DOCKER_RUN_ARGS -v $APPDIR/app/www:/etc/localcoda/www:ro"
  fi

  #Start the container in the background
  log "Starting containter $EXECUTION_NAME..."
  docker run $DOCKER_RUN_ARGS --name "$EXECUTION_NAME" -l "readyurl=$READY_URL" -l "instanceid=$LOCAL_UUID" -l "tutorialpath=${TUTORIAL_DIR%/}/$INDEX_FILE" -l "maxtime=$TUTORIAL_MAX_TIME" -l "starttime=`date -u +%s`" -d --hostname "$IMAGE_HOSTNAME" -e LOCALCODA_OPTIONS="$INDEX_FILE,$EXT_PROTO,$EXT_EXITHOST,$EXT_MAINHOST,$EXT_PROXYHOST,$TUTORIAL_MAX_TIME,$TUTORIAL_EXIT_ON_DISCONNECT" -p $LOCAL_INT_IPPORT:$REMOTE_PORT --rm -it "$IMAGE_TORUN" >/dev/null
  [[ $? -ne 0 ]] && error 1 "Failed to start container"

  #Start sidecar to terminate container after given startup time.
  if [[ "$TUTORIAL_MAX_TIME" != "-1" ]]; then
    nohup bash -c "read -rt \"$TUTORIAL_MAX_TIME\" <> <(:) || :;docker exec \"$EXECUTION_NAME\" /usr/sbin/poweroff; docker stop \"$EXECUTION_NAME\"" </dev/null &>/dev/null &
  fi

  #Wait for the backend to be ready
  if $WAIT_FOR_START; then
    log "Waiting for $EXECUTION_NAME to start..."
    WAIT_TIMEOUT=60
    READY_STATE=1
    while [[ "$READY_STATE" -ne 0 && $WAIT_TIMEOUT -gt 0 ]]; do
      sleep 1
      docker exec "$EXECUTION_NAME" bash -c '[[ -e /etc/localcoda/ready ]]'
      READY_STATE=$?
      WAIT_TIMEOUT=$(( --WAIT_TIMEOUT ))
    done
    [[ $WAIT_TIMEOUT -eq 0 ]] && error 44 "Timeout while waiting for tutorial to start... use backend_ls command to get more info..."

    #Tutorial is started
    log "Your tutorial is ready and accessible from:"
    echo "$READY_URL"
  else
    log "Your tutorial is starting. You can check its status with ./backend_ls.sh"
    echo $LOCAL_UUID
  fi
elif [[ $ORCHESTRATION_ENGINE == "kubernetes" ]]; then

  #Check we are not using a local dir, as this is not accessible from kubernetes
  [[ "${TUTORIAL_DIR:0:1}" == "/" ]] && error 55 "Kubernetes orchestator can support only volumes hosting local dirs"

  #Check runtime engine
  [[ $VIRT_ENGINE != "docker" && $VIRT_ENGINE == "sysbox" ]] && error 32 "Virtualization engine $VIRT_ENGINE not supported in kubernetes mode"

  #Check maximum parallel executions (if reached)
  if [[ -n "$INSTANCE_USERNAME" && -n "$MAXIMUM_RUN_PER_USER" && "$MAXIMUM_RUN_PER_USER" -gt 0 ]]; then
    running_instances="`kubectl get pod -n $KUBERNETES_NAMESPACE --selector "localcoda-user=$INSTANCE_USERNAME" -o name | wc -l`"
    [[ "$running_instances" -ge "$MAXIMUM_RUN_PER_USER" ]] && error 42 "Maximum runs per user reached"
  fi

  {
    cat << EOF
apiVersion: batch/v1
kind: Job
metadata:
  name: $EXECUTION_NAME
  labels:
    localcoda-instanceid: "$LOCAL_UUID"
    localcoda-user: "$INSTANCE_USERNAME"
spec:
  completions: 1
  parallelism: 1
  backoffLimit: 0
  ttlSecondsAfterFinished: 0
EOF
    [[ "$TUTORIAL_MAX_TIME" -ne -1 ]] && echo "  activeDeadlineSeconds: $TUTORIAL_MAX_TIME"
    cat << EOF
  template:  
    metadata:
      labels:
        localcoda-instanceid: "$LOCAL_UUID"
        localcoda-user: "$INSTANCE_USERNAME"
      annotations:
        readyurl: "$READY_URL"
        tutorialpath: "${TUTORIAL_DIR%/}/$INDEX_FILE"
        maxtime: "$TUTORIAL_MAX_TIME"
        starttime: "`date -u +%s`"
EOF
    [[ $VIRT_ENGINE == "sysbox" ]] && echo "        io.kubernetes.cri-o.userns-mode: \"auto:size=65536\"
    runtimeClassName: sysbox-runc"
    cat <<EOF
    spec:
      hostname: $IMAGE_HOSTNAME
      containers:
      - name: app
        image: $IMAGE_TORUN
EOF
    [[ $VIRT_ENGINE == "docker" ]] && cat <<EOF
        securityContext:
          privileged: true
EOF
    cat <<EOF
        env:
        - name: LOCALCODA_OPTIONS
          value: "$INDEX_FILE,$EXT_PROTO,$EXT_EXITHOST,$EXT_MAINHOST,$EXT_PROXYHOST,$TUTORIAL_MAX_TIME,$TUTORIAL_EXIT_ON_DISCONNECT"
        ports:
        - containerPort: 1
        volumeMounts:
        - mountPath: /etc/localcoda/tutorial
          name: tutorials-path
          subPath: $TUTORIAL_DIR
EOF
    [[ "$BACKEND_T_MODE" == "ro" ]] && echo "          readOnly: true"
    cat <<EOF
        startupProbe:
          exec:
            command:
            - cat
            - /etc/localcoda/ready
          initialDelaySeconds: 1
          periodSeconds: 1
          failureThreshold: 60
        lifecycle:
          preStop:
            exec:
              command: ["/usr/sbin/poweroff"]
        resources:
          limits:
            memory: "$IMAGE_MEMORY_LIMIT"
            cpu: "$IMAGE_CPU_LIMIT"
      restartPolicy: Never
EOF
    if [[ -n "$KUBERNETES_BK_DNS" ]]; then
      cat << EOF
      dnsPolicy: "None"
      dnsConfig:
        nameservers:
EOF
      for dnses in ${KUBERNETES_BK_DNS//,/ }; do
        echo "        - $dnses"
      done
    fi
    cat << EOF
      volumes:
      - name: tutorials-path
        persistentVolumeClaim:
          claimName: $TUTORIALS_VOLUME
---
apiVersion: v1
kind: Service
metadata:
  name: $EXECUTION_NAME
spec:
  selector:
    localcoda-instanceid: "$LOCAL_UUID"
  ports:
    - protocol: TCP
      port: 80
      targetPort: 1
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: $EXECUTION_NAME-app
spec:
  ingressClassName: nginx
  rules:
  - host: "$EXT_MAINHOST"
    http:
      paths:
      - pathType: Prefix
        path: "/"
        backend:
          service:
            name: $EXECUTION_NAME
            port:
              number: 80
---
EOF
  #Generate external proxyhost regex for nginx
  EXT_PROXYHOST_REGEX="${EXT_PROXYHOST/PORT/[0-9]+}"
  EXT_PROXYHOST_REGEX="${EXT_PROXYHOST_REGEX%:*}"
  EXT_PROXYHOST_REGEX="~^${EXT_PROXYHOST_REGEX//./\.}$"
  EXT_PROXYHOST_80="${EXT_PROXYHOST//PORT/80}"
  EXT_PROXYHOST_80="${EXT_PROXYHOST_80%:*}"
cat <<EOF
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: $EXECUTION_NAME-proxy
  annotations:
    nginx.ingress.kubernetes.io/server-alias: "$EXT_PROXYHOST_REGEX"
spec:
  ingressClassName: nginx
  rules:
  - host: "$EXT_PROXYHOST_80"
    http:
      paths:
      - pathType: Prefix
        path: "/"
        backend:
          service:
            name: $EXECUTION_NAME
            port:
              number: 80
EOF
  } | kubectl -n "$KUBERNETES_NAMESPACE" apply -f - >&2
  [[ $? -ne 0 ]] && error 54 "Failed to start backend pod"

  #Patch service to make them be deleted once the pod is deleted
  cat <<EOF | kubectl patch -n "$KUBERNETES_NAMESPACE" service/$EXECUTION_NAME ingress/$EXECUTION_NAME-app ingress/$EXECUTION_NAME-proxy --patch-file=/dev/stdin >&2
metadata:
  ownerReferences:
  - apiVersion: batch/v1
    kind: Job
    name: "$EXECUTION_NAME"
    uid: "`kubectl -n "$KUBERNETES_NAMESPACE" get job $EXECUTION_NAME -o jsonpath='{.metadata.uid}'`"
EOF
  [[ $? -ne 0 ]] && error 54 "Failed to tie services to backend pod"

  #Wait for pod to be ready (if requested)
  if $WAIT_FOR_START; then
    log "Waiting for $EXECUTION_NAME to start..."
    kubectl -n "$KUBERNETES_NAMESPACE" wait --for=condition=Ready pod -l job-name=$EXECUTION_NAME --timeout=60s >&2

    #Tutorial is started
    log "Your tutorial is ready and accessible from:"
    echo "$READY_URL"
  else
    log "Your tutorial is starting. You can check its status with ./backend_ls.sh"
    echo "$LOCAL_UUID"
  fi

fi
#all done correctly if we are at this point
exit 0
